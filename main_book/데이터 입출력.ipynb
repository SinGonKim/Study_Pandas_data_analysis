{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c791625",
   "metadata": {},
   "source": [
    "# 외부 파일 읽어오기\n",
    "|File Format|Reader|Writer|\n",
    "|-----------|------|------|\n",
    "|CSV|read_csv|to_csv|\n",
    "|JSON|read_json|to_json|\n",
    "|HTML|read_html|to_html|\n",
    "|SQL|read_sql|to_sql|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570130d",
   "metadata": {},
   "source": [
    "## csv 파일\n",
    "데이터 값을 쉼표(,)로 구분하고 있다는 의미로 CSV(comma-separated values)라고 부르는 텍스트 파일이다.  \n",
    "쉼표(,)로 열을 구분하고 줄바꿈으로 행을 구분한다.  \n",
    "- csv 파일 => 데이터 프레임: pandas.read_csv(\"파일 경로(이름)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e233b175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index            date  duration  item    month   network network_type\n",
      "0        0  15/10/14 06:58    34.429  data  2014-11      data         data\n",
      "1        1  15/10/14 06:58    13.000  call  2014-11  Vodafone       mobile\n",
      "2        2  15/10/14 14:46    23.000  call  2014-11    Meteor       mobile\n",
      "3        3  15/10/14 14:48     4.000  call  2014-11     Tesco       mobile\n",
      "4        4  15/10/14 17:27     4.000  call  2014-11     Tesco       mobile\n",
      "..     ...             ...       ...   ...      ...       ...          ...\n",
      "825    825  13/03/15 00:38     1.000   sms  2015-03     world        world\n",
      "826    826  13/03/15 00:39     1.000   sms  2015-03  Vodafone       mobile\n",
      "827    827  13/03/15 06:58    34.429  data  2015-03      data         data\n",
      "828    828  14/03/15 00:13     1.000   sms  2015-03     world        world\n",
      "829    829  14/03/15 00:16     1.000   sms  2015-03     world        world\n",
      "\n",
      "[830 rows x 7 columns]\n",
      "\n",
      "\n",
      "         0               1         2     3        4         5             6\n",
      "0    index            date  duration  item    month   network  network_type\n",
      "1        0  15/10/14 06:58    34.429  data  2014-11      data          data\n",
      "2        1  15/10/14 06:58        13  call  2014-11  Vodafone        mobile\n",
      "3        2  15/10/14 14:46        23  call  2014-11    Meteor        mobile\n",
      "4        3  15/10/14 14:48         4  call  2014-11     Tesco        mobile\n",
      "..     ...             ...       ...   ...      ...       ...           ...\n",
      "826    825  13/03/15 00:38         1   sms  2015-03     world         world\n",
      "827    826  13/03/15 00:39         1   sms  2015-03  Vodafone        mobile\n",
      "828    827  13/03/15 06:58    34.429  data  2015-03      data          data\n",
      "829    828  14/03/15 00:13         1   sms  2015-03     world         world\n",
      "830    829  14/03/15 00:16         1   sms  2015-03     world         world\n",
      "\n",
      "[831 rows x 7 columns]\n",
      "\n",
      "\n",
      "     index            date  duration  item    month   network network_type\n",
      "0        0  15/10/14 06:58    34.429  data  2014-11      data         data\n",
      "1        1  15/10/14 06:58    13.000  call  2014-11  Vodafone       mobile\n",
      "2        2  15/10/14 14:46    23.000  call  2014-11    Meteor       mobile\n",
      "3        3  15/10/14 14:48     4.000  call  2014-11     Tesco       mobile\n",
      "4        4  15/10/14 17:27     4.000  call  2014-11     Tesco       mobile\n",
      "..     ...             ...       ...   ...      ...       ...          ...\n",
      "825    825  13/03/15 00:38     1.000   sms  2015-03     world        world\n",
      "826    826  13/03/15 00:39     1.000   sms  2015-03  Vodafone       mobile\n",
      "827    827  13/03/15 06:58    34.429  data  2015-03      data         data\n",
      "828    828  14/03/15 00:13     1.000   sms  2015-03     world        world\n",
      "829    829  14/03/15 00:16     1.000   sms  2015-03     world        world\n",
      "\n",
      "[830 rows x 7 columns]\n",
      "\n",
      "\n",
      "                 date  duration  item    month   network network_type\n",
      "index                                                                \n",
      "0      15/10/14 06:58    34.429  data  2014-11      data         data\n",
      "1      15/10/14 06:58    13.000  call  2014-11  Vodafone       mobile\n",
      "2      15/10/14 14:46    23.000  call  2014-11    Meteor       mobile\n",
      "3      15/10/14 14:48     4.000  call  2014-11     Tesco       mobile\n",
      "4      15/10/14 17:27     4.000  call  2014-11     Tesco       mobile\n",
      "...               ...       ...   ...      ...       ...          ...\n",
      "825    13/03/15 00:38     1.000   sms  2015-03     world        world\n",
      "826    13/03/15 00:39     1.000   sms  2015-03  Vodafone       mobile\n",
      "827    13/03/15 06:58    34.429  data  2015-03      data         data\n",
      "828    14/03/15 00:13     1.000   sms  2015-03     world        world\n",
      "829    14/03/15 00:16     1.000   sms  2015-03     world        world\n",
      "\n",
      "[830 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = '../phone_data.csv'\n",
    "\n",
    "# read_csv() 함수로 데이터프레임 변환. 변수 df1에 저장\n",
    "df1 = pd.read_csv(file_path)\n",
    "print(df1)\n",
    "print('\\n')\n",
    "\n",
    "# read_csv() 함수로 데이터프레임 변환. 변수 df2에 저장. header = None 옵션\n",
    "df2 = pd.read_csv(file_path, header=None)\n",
    "print(df2)\n",
    "print('\\n')\n",
    "\n",
    "# read_csv() 함수로 데이터프레임 변환. 변수 df3에 저장. index_col=None 옵션\n",
    "df3 = pd.read_csv(file_path, index_col = None)\n",
    "print(df3)\n",
    "print('\\n')\n",
    "\n",
    "# read_csv() 함수로 데이터프레임 변환. 변수 df4에 저장. index_col = 'c0' 옵션\n",
    "df4 = pd.read_csv(file_path, index_col='index')\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6603b2a3",
   "metadata": {},
   "source": [
    "### 옵션\n",
    "|옵션|설명|\n",
    "|----|----|\n",
    "|path|파일의 위치(파일명 포함),URL|\n",
    "|sep(또는 delimiter)|텍스트 데이터를 필드별로 구분하는 문자|\n",
    "|header|<p>열 이름으로 사용될 행의 번호(기본값0)<br>header가 없고 첫 행부터 데이터가 있는 경우 None으로 지정 가능</p>|\n",
    "|index_col|행 인덱스로 사용할 열의 번호 또는 열 이름|\n",
    "|names|열 이름으로 사용할 문자열 리스트|\n",
    "|skiprows|<p>처음 몇줄을 skip 할 것인지 설정(숫자 입력)<br>skip하려는 행의 번호를 담은 리스트로 설정 가능(예: [1, 3, 5])</p>|\n",
    "|parse_dates|날짜 텍스트를 datetime64로 변한할 것인지 설정(기본값은 False)|\n",
    "|skip_footer|마지막 몇 줄을 skip할 것인지 설정(숫자입력)|\n",
    "|encoding| 텍스트 인코딩 종류를 설정(예:'utf-8')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6039a61e",
   "metadata": {},
   "source": [
    "## Excel 파일\n",
    "Excel 파일(확장자: .xlsx)의 행과 열은 데이터프레임의 행, 열로 일대일 대응된다.  \n",
    "read_excel() 함수의 사용법은 앞에서 살펴본 read_csv() 함수와 거의 비슷하다.  \n",
    "- Excel 파일=> 데이터프레임: pandas.read_excel(\"파일경로(이름)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5581c140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0               Unnamed: 1           Unnamed: 2  \\\n",
      "0          NaN  부스트캠프 AI Tech 2기 일별 시간표                  NaN   \n",
      "1          NaN                      NaN                  NaN   \n",
      "2          NaN                      NaN                    월   \n",
      "3        week1                       시간  2021-08-02 00:00:00   \n",
      "4          NaN              10:00~10:10        출석체크  및 학습 시작   \n",
      "..         ...                      ...                  ...   \n",
      "176        NaN             16:30~ 18:00                  NaN   \n",
      "177        NaN              18:00~19:00                  NaN   \n",
      "178        NaN              19:00~19:10                  NaN   \n",
      "179        NaN                      NaN                  NaN   \n",
      "180        NaN  5주 이론, 15주 프로젝트 과정으로 진행                  NaN   \n",
      "\n",
      "              Unnamed: 3           Unnamed: 4           Unnamed: 5  \\\n",
      "0                    NaN                  NaN                  NaN   \n",
      "1                    NaN                  NaN                  NaN   \n",
      "2                      화                    수                    목   \n",
      "3    2021-08-03 00:00:00  2021-08-04 00:00:00  2021-08-05 00:00:00   \n",
      "4          출석체크  및 학습 시작        출석체크  및 학습 시작        출석체크  및 학습 시작   \n",
      "..                   ...                  ...                  ...   \n",
      "176                  NaN                  NaN                  NaN   \n",
      "177                  NaN                  NaN                  NaN   \n",
      "178                  NaN                  NaN                  NaN   \n",
      "179                  NaN                  NaN                  NaN   \n",
      "180                  NaN                  NaN                  NaN   \n",
      "\n",
      "              Unnamed: 6 Unnamed: 7                      Unnamed: 8  \\\n",
      "0                    NaN        NaN                             NaN   \n",
      "1                    NaN        NaN                             NaN   \n",
      "2                      금       교과정보                             NaN   \n",
      "3    2021-08-06 00:00:00       훈련강사                             교과목   \n",
      "4          출석체크  및 학습 시작  최성철/\\n임성빈  Python Basics for AI / AI Math   \n",
      "..                   ...        ...                             ...   \n",
      "176                  NaN        NaN                             NaN   \n",
      "177                  NaN        NaN                             NaN   \n",
      "178                  NaN        NaN                             NaN   \n",
      "179                  NaN        NaN                             NaN   \n",
      "180                  NaN        NaN                             NaN   \n",
      "\n",
      "    Unnamed: 9 Unnamed: 10 Unnamed: 11 Unnamed: 12 Unnamed: 13 Unnamed: 14  \n",
      "0          800         NaN         200         600         NaN         NaN  \n",
      "1          NaN         NaN         NaN         NaN         NaN         NaN  \n",
      "2          NaN         NaN         온라인        오프라인         NaN         NaN  \n",
      "3         교육시간          장소         NaN         NaN         NaN         NaN  \n",
      "4           40         온라인          40         NaN         NaN         NaN  \n",
      "..         ...         ...         ...         ...         ...         ...  \n",
      "176        NaN         NaN         NaN         NaN         NaN         NaN  \n",
      "177        NaN         NaN         NaN         NaN         NaN         NaN  \n",
      "178        NaN         NaN         NaN         NaN         NaN         NaN  \n",
      "179        NaN         NaN         NaN         NaN         NaN         NaN  \n",
      "180        NaN         NaN         NaN         NaN         NaN         NaN  \n",
      "\n",
      "[181 rows x 15 columns]\n",
      "\n",
      "\n",
      "        0                        1                    2                    3   \\\n",
      "0      NaN                      NaN                  NaN                  NaN   \n",
      "1      NaN  부스트캠프 AI Tech 2기 일별 시간표                  NaN                  NaN   \n",
      "2      NaN                      NaN                  NaN                  NaN   \n",
      "3      NaN                      NaN                    월                    화   \n",
      "4    week1                       시간  2021-08-02 00:00:00  2021-08-03 00:00:00   \n",
      "..     ...                      ...                  ...                  ...   \n",
      "177    NaN             16:30~ 18:00                  NaN                  NaN   \n",
      "178    NaN              18:00~19:00                  NaN                  NaN   \n",
      "179    NaN              19:00~19:10                  NaN                  NaN   \n",
      "180    NaN                      NaN                  NaN                  NaN   \n",
      "181    NaN  5주 이론, 15주 프로젝트 과정으로 진행                  NaN                  NaN   \n",
      "\n",
      "                      4                    5                    6     7    8   \\\n",
      "0                    NaN                  NaN                  NaN   NaN  NaN   \n",
      "1                    NaN                  NaN                  NaN   NaN  NaN   \n",
      "2                    NaN                  NaN                  NaN   NaN  NaN   \n",
      "3                      수                    목                    금  교과정보  NaN   \n",
      "4    2021-08-04 00:00:00  2021-08-05 00:00:00  2021-08-06 00:00:00  훈련강사  교과목   \n",
      "..                   ...                  ...                  ...   ...  ...   \n",
      "177                  NaN                  NaN                  NaN   NaN  NaN   \n",
      "178                  NaN                  NaN                  NaN   NaN  NaN   \n",
      "179                  NaN                  NaN                  NaN   NaN  NaN   \n",
      "180                  NaN                  NaN                  NaN   NaN  NaN   \n",
      "181                  NaN                  NaN                  NaN   NaN  NaN   \n",
      "\n",
      "       9    10   11    12   13   14  \n",
      "0     NaN  NaN  NaN   NaN  NaN  NaN  \n",
      "1     800  NaN  200   600  NaN  NaN  \n",
      "2     NaN  NaN  NaN   NaN  NaN  NaN  \n",
      "3     NaN  NaN  온라인  오프라인  NaN  NaN  \n",
      "4    교육시간   장소  NaN   NaN  NaN  NaN  \n",
      "..    ...  ...  ...   ...  ...  ...  \n",
      "177   NaN  NaN  NaN   NaN  NaN  NaN  \n",
      "178   NaN  NaN  NaN   NaN  NaN  NaN  \n",
      "179   NaN  NaN  NaN   NaN  NaN  NaN  \n",
      "180   NaN  NaN  NaN   NaN  NaN  NaN  \n",
      "181   NaN  NaN  NaN   NaN  NaN  NaN  \n",
      "\n",
      "[182 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read_excel() 함수로 데이터프레임 변환\n",
    "df1 = pd.read_excel('./시간표.xlsx')\n",
    "df2 = pd.read_excel('./시간표.xlsx', header = None)\n",
    "\n",
    "print(df1)\n",
    "print('\\n')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d078aa7",
   "metadata": {},
   "source": [
    "## JSON 파일\n",
    "JSON 파일은 데이터 공유를 목적으로 개발된 특수한 파일 형식이다.  \n",
    "파이썬 딕셔너리와 비숫하게 \"key : value\" 구조를 갖는데, 구조가 중첩되는 방식에 따라 다르게 적용한다.\n",
    "- JSON파일 => 데이터프레임: pandas.read_json(\"파일경로(이름)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7267419f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           name  year        developer opensource\n",
      "pandas           2008    Wes Mckinneye       True\n",
      "NumPy            2006  Travis Oliphant       True\n",
      "matplotlib       2003   John D. Hunter       True\n",
      "\n",
      "\n",
      "Index(['pandas', 'NumPy', 'matplotlib'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"./sample.json\")\n",
    "print(df)\n",
    "print('\\n')\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50362a",
   "metadata": {},
   "source": [
    "# 웹(Web)에서 가져오기\n",
    "## HTML 웹 페이지에서 표 속성 가져오기\n",
    "판다스 read_html() 함수는 HTML 웹 페이지에 있는 <table> 태구에서 표 형식의 데이터를 모두 찾아서 데이터프레임으로 변환한다.  \n",
    "표 데이터들은 각각 별도의 데이터프레임으로 변환되기 때문에 여러개의 데이터프레임(표)을 원소로 갖는 리스트가 반환된다.\n",
    "- HTML 표 속성 읽기 : pandas.read_html(\"웹 주소(URL)\" 또는 \"HTML 파일 경로(이름)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e36b4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "\n",
      "tables[0]\n",
      "                  Job             prepare\n",
      "0             actuary        prepare exam\n",
      "1  Fiance Engineering  go graduate school\n",
      "\n",
      "\n",
      "                               prepare\n",
      "Job                                   \n",
      "actuary                   prepare exam\n",
      "Fiance Engineering  go graduate school\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# HTML 파일 경로 or 웹 페이지 주소를 url 변수에 저장\n",
    "url = './sample.html'\n",
    "\n",
    "#HTML 웹페이지 표(table)를 가져와서 데이터프레임으로 변환\n",
    "tables = pd.read_html(url)\n",
    "\n",
    "# 표(table)의 개수 확인\n",
    "print(len(tables))\n",
    "print('\\n')\n",
    "\n",
    "# tables 리스트 원소를 iteration하면서 각각 화면 출력\n",
    "for i in range(len(tables)):\n",
    "    print(\"tables[%s]\" %i)\n",
    "    print(tables[i])\n",
    "    print('\\n')\n",
    "# 파이썬 패키지 정보가 들어 있는 두 번째 데이터프레임을 선택하여 df 변수에 저장\n",
    "df = tables[0]\n",
    "\n",
    "# '직업' 열을 인덱스로 지정\n",
    "df.set_index(['Job'], inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96811103",
   "metadata": {},
   "source": [
    "## 웹 스크래핑\n",
    "BeautifulSoup 등 웹 스크래핑(scraping)도구로 수집한 데이터를 판다스 데이터프레임으로 정리하는 방법을 설명한다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1aef1ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "#위키피디아 미국 ETF 웹 페이지에서 필요한 정보를 스크래핑하여 딕셔너리 형태로 변수 etfs에 저장\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_American_exchange-traded_funds\"\n",
    "resp = requests.get(url)\n",
    "soup = BeautifulSoup(resp.text, 'lxml')\n",
    "rows = soup.select('div > ul > li')\n",
    "\n",
    "etfs = {}\n",
    "for row in rows:\n",
    "    \n",
    "    try:\n",
    "        etf_name = re.findall('^(.*)\\(NYSE', row.text)\n",
    "        etf_market = re.findall('\\((.*)\\|', row.text)\n",
    "        etf_ticker = re.findall('NYSE Arca\\|(.*)\\)', row.text)\n",
    "        \n",
    "        if (len(etf_ticker) > 0) & (len(etf_market) > 0) & (len(etf_name) > 0):\n",
    "            etfs[etf_ticker[0]] = [etf_market[0], etf_name[0]]\n",
    "    except AttributeError as err:\n",
    "        pass\n",
    "\n",
    "# etfs 딕셔너리 출력\n",
    "print(etfs)\n",
    "print('\\n')\n",
    "# etfs 딕셔너리를 데이터프레임으로 변환\n",
    "df = pd.DataFrame(etfs)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e657ab0a",
   "metadata": {},
   "source": [
    "### 데이터베이스[database]에서 판다스로 데이터를 가져올 수 있을까?\n",
    "판다스 read_sql() 함수를 이용하면 SQL 쿼리를 가지고 데이터베이스로부터 데이터를 불러올 수 있다.  \n",
    "이때 읽어온 데이터는 데이터프레임 포맷으로 저장된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1615bed1",
   "metadata": {},
   "source": [
    "# API 활용하여 데이터 수집하기\n",
    "\n",
    "|구글 지오코딩 API 발급절차|\n",
    "|--------------------------|\n",
    "|구글 지도 서비스(https://cloud.google.com/maps-platform/places/?hl=ko) 접속|\n",
    "|API 설정|\n",
    "|사용자 인증|\n",
    "|API 키 발급|\n",
    "\n",
    "1. Anaconda Prompt를 실행\n",
    "2. 콘다 설치명령 conda install -c conda-forge googlemaps\n",
    "3. 설치여부 'y'입력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6582d505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 서울시청\n",
      "1\n",
      "2 국립국악원\n",
      "2\n",
      "3 해운대해수욕장\n",
      "3\n",
      "\n",
      "\n",
      "        위도 경도\n",
      "서울시청         \n",
      "국립국악원        \n",
      "해운대해수욕장      \n"
     ]
    }
   ],
   "source": [
    "import googlemaps\n",
    "import pandas as pd\n",
    "\n",
    "my_key = \"AIzaSyA0Xb5OBQWfkFcNnU7xOqHf6jW2VtHhTf0\" #삭제\n",
    "\n",
    "# 구글 맵스 객체 생성하기\n",
    "maps = googlemaps.Client(key=my_key) #my key 값 입력\n",
    "lat = [] #위도\n",
    "lng = [] #경도\n",
    "\n",
    "places = [\"서울시청\", \"국립국악원\", \"해운대해수욕장\"]\n",
    "\n",
    "i = 0\n",
    "for place in places:\n",
    "    i = i + 1\n",
    "    try:\n",
    "        print(i, place)\n",
    "        # 지오코딩 API 결과값 호출하여 geo_location 변수에 저장\n",
    "        geo_location = map.geocode(places)[0].get('geometry')\n",
    "        lat.append(geo_location['location']['lat'])\n",
    "        lng.append(geo_location['location']['lng'])\n",
    "    except:\n",
    "        lat.append('')\n",
    "        lng.append('')\n",
    "        print(i)\n",
    "\n",
    "# 데이터프레임으로 변환하기\n",
    "df = pd.DataFrame({'위도':lat, '경도':lng}, index=places)\n",
    "print('\\n')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514fad89",
   "metadata": {},
   "source": [
    "# 데이터 저장하기\n",
    "## CSV 파일로 저장\n",
    "판다스 데이터프레임은 2차원 배열로 구조화된 데이터이기 때문에 2차원 구조를 갖는 CSV 파일로 변환할 수 있다.  \n",
    "데이터프레임을 CSV 파일로 저장하려면 to_csv() 메소드를 적용한다.  \n",
    "CSV 파일을 저장할 파일 경로와 파일명을 따옴표 안에 입력한다.  \n",
    "- CSV 파일로 저장 DataFrame 객체.to_csv(\"파일 이름(경로)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01d3f7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      algol basic c++\n",
      "name                 \n",
      "Jerry     A     C  B+\n",
      "Riah     A+     B   C\n",
      "Paul      B    B+  C+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 판다스 DataFrame() 함수로 데이터프레임 변환. 변수 df에 저장\n",
    "data = {'name': ['Jerry', 'Riah', 'Paul'],\n",
    "       'algol' : [\"A\", \"A+\", \"B\"],\n",
    "       'basic' : [ \"C\", \"B\", \"B+\"],\n",
    "       'c++' : ['B+', 'C', 'C+'],\n",
    "       }\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index('name', inplace=True) # name 열을 인덱스로 지정\n",
    "print(df)\n",
    "\n",
    "# to_csv() 메소드를 사용하여 CSV 파일로 내보내기. 파일명은 df_sample.csv로 저장\n",
    "df.to_csv('./df_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a2045",
   "metadata": {},
   "source": [
    "## JSON 파일로 저장\n",
    "데이터프레임을 JSON 파일로 저장하려면 to_json() 메소드를 이용한다. JSON 파일의 이름을 저장하려는 파일 경로와 함께 따옴표 안에 입력한다.  \n",
    "- JSON 파일로 저장: DataFrame 객체.to_json(\"파일 이름(경로)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf9d4da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      algol basic c++\n",
      "name                 \n",
      "Jerry     A     C  B+\n",
      "Riah     A+     B   C\n",
      "Paul      B    B+  C+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 판다스 DataFrame() 함수로 데이터프레임 변환. 변수 df에 저장\n",
    "data = {'name': ['Jerry', 'Riah', 'Paul'],\n",
    "       'algol' : [\"A\", \"A+\", \"B\"],\n",
    "       'basic' : [ \"C\", \"B\", \"B+\"],\n",
    "       'c++' : ['B+', 'C', 'C+'],\n",
    "       }\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index('name', inplace=True) # name 열을 인덱스로 지정\n",
    "print(df)\n",
    "\n",
    "df.to_json(\"./df_sample.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571a7def",
   "metadata": {},
   "source": [
    "## Excel 파일로 저장\n",
    "데이터프레임 Excel 파일과 아주 유사한 구조를 갖는다.  \n",
    "데이터프레임의 행과 열은 Excel 파일의 행과 열로 일대일로 대응된다.  \n",
    "데이터프레임을 Excel 파일로 저장할 때는 to_excel()메소드를 적용한다.  \n",
    "단 to_excel() 메소드를 사용하려면 openpyxl 라이브러리를 사전에 설치해야 한다.  \n",
    "아나콘다 배포판에는 openpyxl 라이브러리가 기본 제공되므로 따로 설치하지 않아도 된다.  \n",
    "- Excel 파일로 저장: DataFrame 객체.to_excel(\"파일이름(경로)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb9200f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      algol basic c++\n",
      "name                 \n",
      "Jerry     A     C  B+\n",
      "Riah     A+     B   C\n",
      "Paul      B    B+  C+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 판다스 DataFrame() 함수로 데이터프레임 변환. 변수 df에 저장\n",
    "data = {'name': ['Jerry', 'Riah', 'Paul'],\n",
    "       'algol' : [\"A\", \"A+\", \"B\"],\n",
    "       'basic' : [\"C\", \"B\", \"B+\"],\n",
    "       'c++' : [\"B+\", \"C\", \"C+\"],\n",
    "       }\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index('name', inplace = True) # name 열을 인덱스로 지정\n",
    "print(df)\n",
    "\n",
    "# to_excel() 메소드를 사용하여 Excel 파일로 내보내기. 파일명은 df_sample.xlsx로 저장\n",
    "df.to_excel(\"./df_sample.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7396c558",
   "metadata": {},
   "source": [
    "## 여러개의 데이터프레임을 하나의 Excel 파일로 저장\n",
    "- 데이터프레임 여러 개를 Excel 파일로 저장: pandas.ExcelWriter(\"파일 이름(경로)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1bdc2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      algol basic c++\n",
      "name                 \n",
      "Jerry     A     C  B+\n",
      "Riah     A+     B   C\n",
      "Paul      B    B+  C+\n",
      "\n",
      "\n",
      "    c1  c2  c3  c4\n",
      "c0                \n",
      "1    4   7  10  13\n",
      "2    5   8  11  14\n",
      "3    6   9  12  15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 판다스 DataFrame() 함수로 데이터프레임 변환. 변수 df1, df2에 저장\n",
    "data1 = {'name': ['Jerry', 'Riah', 'Paul'],\n",
    "        'algol' : ['A', 'A+', 'B'],\n",
    "        'basic' : [\"C\", \"B\", \"B+\"],\n",
    "        'c++' : [\"B+\", \"C\", \"C+\"]}\n",
    "data2 = {'c0':[1,2,3],\n",
    "        'c1':[4,5,6],\n",
    "        'c2':[7,8,9],\n",
    "        'c3':[10,11,12],\n",
    "        'c4' : [13,14,15]}\n",
    "df1 = pd.DataFrame(data1)\n",
    "df1.set_index('name', inplace = True)\n",
    "print(df1)\n",
    "print('\\n')\n",
    "\n",
    "df2 = pd.DataFrame(data2)\n",
    "df2.set_index('c0', inplace = True)\n",
    "print(df2)\n",
    "\n",
    "# df1을 'sheet1'으로, df2를 'sheet2'로 저장(Excel 파일명은 \"df_excelwriter.xlsx\")\n",
    "writer = pd.ExcelWriter(\"./df_excelwriter.xlsx\")\n",
    "df1.to_excel(writer, sheet_name=\"sheet1\")\n",
    "df2.to_excel(writer, sheet_name=\"sheet2\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3df7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
